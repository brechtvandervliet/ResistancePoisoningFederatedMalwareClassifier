from multiprocessing import Pool

import numpy as np
from scipy import sparse
from collections import defaultdict

from lim_code.defense_type_enum import DefenseType
from lim_code.knowledge_scenario_enum import KnowledgeScenario
from lim_code.lim_logger import logger
from lim_code.model_train.safew import safew
from lim_code.model_train.malware_classifier import MalwareSAFEWClient
from lim_code.model_test import results, evaluate_lim
from lim_code.model_train.adversarial import is_poisoned, poison_weights
from lim_code.model_train.save_data import save_data


class LiM(object):
    """
    The LiM classifier is a federated binary SAFEW for malware
    """

    def __init__(self,
                 data,
                 baseline_model,
                 base_models,
                 p_malware=0.1,
                 p_install=0.2,
                 n_clients=20,
                 adversarial_proportion=0.5,
                 n_max_apps_per_round=5,
                 n_rounds=5,
                 knowledge_scenario=KnowledgeScenario.AGNOSTIC,
                 defense_type=DefenseType.NONE,):
        """
        p_malware: probability of a client installing a malware app
        n_clients: number of clients in the federation
        """
        super(LiM, self).__init__()

        self.data = data
        self.cloud_weights = None
        self.bc_cloud_weights = None  # bc = best case scenario where all clients are honest
        self.wc_cloud_weights = None  # wc = worst case scenario where 50% of clients is malicious and cloud does not have any defenses                                                                                                                          
        self.n_clients = n_clients
        self.adversarial_proportion = adversarial_proportion
        self.clients = []
        self.n_max_apps_per_round = n_max_apps_per_round
        self.p_malware = p_malware
        self.p_install = p_install
        self.n_rounds = n_rounds
        self.federation_round = 0
        self.knowledge_scenario = knowledge_scenario
        self.defense_type = defense_type
        self.baseline_model = baseline_model
        self.base_models = base_models

    def run_federation(self):
        logger.info(f"Round {self.federation_round}")
        self.create_cloud()
        save_data(self.baseline_model, self.base_models, self.data)
        if self.adversarial_proportion > 0:
            # Simulate a blank slate adversarial client
            client = self.create_client_worker([0, True])
            self.data.select_malicious(
                baseline_model=self.baseline_model,
                base_models=self.base_models,
                weights=client.weights)

        # Let adversarial clients find an malicious app in later rounds
        self.create_clients()

        while self.federation_round < self.n_rounds:
            self.federation_round += 1
            logger.info(f"Round {self.federation_round}")
            self.federate_cloud()
            self.federate_clients()
            self.select_malware_app()
            df_tmp = results.to_df()
            df_tmp.to_csv("results_tmp.csv")
            evaluate_lim.plot_cloud(df_tmp)
            evaluate_lim.plot_clients(df_tmp)

        return results.to_df()

    def create_cloud(self):
        data = self.data
        X_train = data.X_train
        y_train = data.y_train
        self.baseline_model.fit(X_train, y_train)
        for model in self.base_models:
            model.fit(X_train, y_train)

        X = data.cloud_X_test
        y_true = data.cloud_y_test

        pred, w = safew(
            baseline_model=self.baseline_model,
            base_models=self.base_models,
            X=X,)
        predictions = {
            "baseline": self.baseline_model.predict(X),
            "no-lim": pred,
            "lim": pred,
            "no-privacy": pred,
            "bc-lim": pred,
            "wc-lim": pred,
        }
        weights = {
            "no-lim": w,
            "lim": w,
            "no-privacy": w,
            "bc-lim": w,
            "wc-lim": w,
        }
        labels = {
            "baseline": y_true,
            "no-lim": y_true,
            "lim": y_true,
            "no-privacy": y_true,
            "bc-lim": y_true,
            "wc-lim": y_true,
        }
        results.add(
            place="cloud",
            federation_round=self.federation_round,
            id_=-1,
            malicious=False,
            poisoned=False,
            wc_poisoned=False,
            bc_poisoned=False,
            labels=labels,
            predictions=predictions,
            weights=weights,
        )
        self.cloud_weights = weights["lim"]
        self.bc_cloud_weights = weights["bc-lim"]
        self.wc_cloud_weights = weights["wc-lim"]

    def create_clients(self):
        n_adversarial = int(self.adversarial_proportion * self.n_clients)
        n_honest = self.n_clients - n_adversarial
        args = [
            [id_, malicious]
            for id_, malicious in zip(
                    list(range(self.n_clients)),
                    [True]*n_adversarial
                    + [False]*n_honest
                    )
            ]

        with Pool() as p:
            clients = p.map(self.create_client_worker, args)

        for client in clients:
            X = client.X_installed
            y_true = client.y_installed
            pred, w = safew(
                baseline_model=self.baseline_model,
                base_models=self.base_models,
                X=X,)
            client.weights = w
            client.bc_weights = w
            client.wc_weights = w
            client.honest_weights = w
            client.wc_honest_weights = w

            predictions = {
                "baseline": self.baseline_model.predict(X),
                "no-lim": pred,
                "lim": pred,
                "bc-lim": pred,
                "wc-lim": pred,
            }
            weights = {
                "no-lim": w,
                "lim": w,
                "bc-lim": w,
                "wc-lim": w,
            }
            labels = {
                "baseline": y_true,
                "no-lim": y_true,
                "lim": y_true,
                "bc-lim": y_true,
                "wc-lim": y_true,
            }
            results.add(
                place="client",
                federation_round=self.federation_round,
                id_=client.id_,
                malicious=client.malicious,
                labels=labels,
                poisoned=False,
                wc_poisoned=False,
                bc_poisoned=False,
                predictions=predictions,
                weights=weights)
        self.clients = clients

    def create_client_worker(self, args):
        id_, malicious = args
        return MalwareSAFEWClient(
            self.data,
            self.cloud_weights,
            malicious,
            id_,
        )

    def federate_cloud(self):

        wc_client_weights = np.mean(
            [client.wc_weights for client in self.clients],
            axis=0)

        bc_weights = [client.bc_weights for client in self.clients]

        ## test 1: randomizing client weights ##
        # I used "LiM (best case)" to check for the effect of randomization
        """
        bc_weights = np.random.rand(self.n_clients, 5)
        bc_weights = bc_weights / bc_weights.sum(axis=1).reshape(self.n_clients, 1)
        """
        ########################################

        bc_client_weights = np.mean(bc_weights, axis=0)
        data = self.data
        X = data.cloud_X_test
        y_true = data.cloud_y_test
        N = data.cloud_N_test

        no_lim_pred, no_lim_weights = safew(
            baseline_model=self.baseline_model,
            base_models=self.base_models,
            X=X,
        )

        all_client_weights = [client.weights for client in self.clients]
        if self.defense_type == DefenseType.DISCARD_IRREGULAR and self.federation_round > 1:
            filtered_client_weights = self.defense_discard_irregular_updates(all_client_weights)
            client_weights = np.mean(filtered_client_weights, axis=0)
        else:  # self.defense_type == DefenseType.NONE
            client_weights = np.mean(all_client_weights, axis=0)

        new_weights = np.mean(
            [client_weights, no_lim_weights],
            axis=0)

        bc_new_weights = np.mean(
            [bc_client_weights, no_lim_weights],
            axis=0)

        ## test 2: equal cloud weights ##
        """
        bc_new_weights = np.mean(
            [bc_client_weights, np.array([0.2, 0.2, 0.2, 0.2, 0.2])],
            axis=0)
        """
        #################################

        wc_new_weights = np.mean(
            [wc_client_weights, no_lim_weights],
            axis=0)

        lim_pred, lim_weights = safew(
            baseline_model=self.baseline_model,
            base_models=self.base_models,
            X=X,
            weights=new_weights,
        )
        bc_lim_pred, bc_lim_weights = safew(
            baseline_model=self.baseline_model,
            base_models=self.base_models,
            X=X,
            weights=bc_new_weights,
        )
        wc_lim_pred, wc_lim_weights = safew(
            baseline_model=self.baseline_model,
            base_models=self.base_models,
            X=X,
            weights=wc_new_weights,
        )
        predictions = {
            "baseline": self.baseline_model.predict(X),
            "no-lim": no_lim_pred,
            "lim": lim_pred,
            "bc-lim": bc_lim_pred,
            "wc-lim": wc_lim_pred,
        }
        weights = {
            "no-lim": no_lim_weights,
            "lim": lim_weights,
            "bc-lim": bc_lim_weights,
            "wc-lim": wc_lim_weights,
        }
        labels = {
            "baseline": y_true,
            "no-lim": y_true,
            "lim": y_true,
            "bc-lim": y_true,
            "wc-lim": y_true,
        }
        results.add(
            place="cloud",
            federation_round=self.federation_round,
            id_=-1,
            malicious=False,
            labels=labels,
            poisoned=False,
            wc_poisoned=False,
            bc_poisoned=False,
            predictions=predictions,
            weights=weights,
        )
        self.cloud_weights = lim_weights
        self.bc_cloud_weights = bc_lim_weights
        self.wc_cloud_weights = wc_lim_weights

    def defense_discard_irregular_updates(self, all_client_weights):
        upper_bound = np.round((self.cloud_weights + np.ones_like(self.cloud_weights)) / 2, 3)
        lower_bound = np.round((self.cloud_weights + np.zeros_like(self.cloud_weights)) / 2, 3)

        filtered_client_weights = []

        for weights in all_client_weights:

            r_weight = np.round(weights, 3)

            total_irregularities = np.sum(r_weight > upper_bound) + np.sum(r_weight < lower_bound)

            if total_irregularities == 0:
                filtered_client_weights.append(weights)
            else:
                logger.info(
                    f"{r_weight} weight has been discarded. Upper bound = {upper_bound} Lower bound = {lower_bound}")

        return filtered_client_weights

    def federate_clients(self):
        args = [[self.n_max_apps_per_round,
                 self.p_install,
                 self.p_malware,
                 client,
                 self.baseline_model,
                 self.base_models,
                 self.cloud_weights,
                 self.bc_cloud_weights,
                 self.wc_cloud_weights,
                 self.federation_round,
                 self.data.X_malicious]
                for client in self.clients]
        with Pool() as p:
            client_r = p.map(update_client_worker, args)

        if self.adversarial_proportion != 0 and self.data.X_malicious is not None:
            compromised_weights = [c["client"].honest_weights for c in client_r if c["client"].malicious]
            honest_client_weights = [c["client"].honest_weights for c in client_r if not c["client"].malicious]
            poisoned_weights = poison_weights(
                self.defense_type,
                self.knowledge_scenario,
                self.base_models,
                self.cloud_weights,
                compromised_weights,
                honest_client_weights,
                self.data.X_malicious)

            wc_compromised_weights = [c["client"].wc_honest_weights for c in client_r if c["client"].malicious]
            wc_honest_client_weights = [c["client"].wc_honest_weights for c in client_r if not c["client"].malicious]
            wc_poisoned_weights = poison_weights(
                DefenseType.NONE,
                self.knowledge_scenario,
                self.base_models,
                self.wc_cloud_weights,
                wc_compromised_weights,
                wc_honest_client_weights,
                self.data.X_malicious)

            args = [[client,
                     self.baseline_model,
                     self.base_models,
                     self.data.X_malicious,
                     poisoned_weights,
                     wc_poisoned_weights]
                    for client in client_r]
            with Pool() as p:
                client_r = p.map(update_malicious_client_worker, args)

        for worker in client_r:
            for i, client in enumerate(self.clients):
                if worker["client"].id_ == client.id_:
                    self.clients[i] = worker["client"]
            weights = worker["weights"]
            poisoned, wc_poisoned, bc_poisoned = False, False, False
            if self.data.X_malicious is not None:
                bc_poisoned_weights = weights["bc-lim"]
                if worker["client"].malicious and "poisoned" in weights:
                    poisoned_weights = weights["poisoned"]
                    wc_poisoned_weights = weights["wc_poisoned"]
                else:
                    poisoned_weights = weights["lim"]
                    wc_poisoned_weights = weights["wc-lim"]
                poisoned = is_poisoned(
                    baseline_model=self.baseline_model,
                    base_models=self.base_models,
                    poisoned_weights=poisoned_weights,
                    X_malicious=self.data.X_malicious,
                )
                wc_poisoned = is_poisoned(
                    baseline_model=self.baseline_model,
                    base_models=self.base_models,
                    poisoned_weights=wc_poisoned_weights,
                    X_malicious=self.data.X_malicious,
                )
                bc_poisoned = is_poisoned(
                    baseline_model=self.baseline_model,
                    base_models=self.base_models,
                    poisoned_weights=bc_poisoned_weights,
                    X_malicious=self.data.X_malicious,
                )
            results.add(place="client",
                        federation_round=self.federation_round,
                        id_=worker["id"],
                        malicious=worker["client"].malicious,
                        labels=worker["labels"],
                        predictions=worker["predictions"],
                        poisoned=poisoned,
                        wc_poisoned=wc_poisoned,
                        bc_poisoned=bc_poisoned,  # to check if malicious app is not just a false negative
                        weights=worker["weights"])

    def select_malware_app(self):
        ############################
        ## Select a malicious app ##
        ############################
        # federation_round > 1: during round 0 clients do not receive any federated weights,
        # so only from round two onwards is poisoning possible.
        if self.data.X_malicious is None and self.federation_round > 1:
            if self.knowledge_scenario == KnowledgeScenario.AGR_UPDATES or self.knowledge_scenario == KnowledgeScenario.UPDATES_ONLY:
                # adversary knows weights of all clients
                client_weights = np.mean([client.weights for client in self.clients], axis=0)
            else:
                # adversary only knows weights of his own devices
                client_weights = np.mean([client.weights for client in self.clients if client.malicious], axis=0)

            weights_to_poison = np.mean(
                [client_weights, self.cloud_weights],
                axis=0)
            print("weights to poison " + str(weights_to_poison))
            self.data.select_malicious(
                baseline_model=self.baseline_model,
                base_models=self.base_models,
                weights=weights_to_poison)
            found_app = self.data.X_malicious is not None
            # Install new selected malicious app in all malicious clients
            if found_app:
                for c in self.clients:
                    if c.malicious: c.install_malicious_app(self.data.X_malicious)


def update_client_worker(args):
    n_max_apps, p_install, p_malware, client, baseline_model, base_models, cloud_weights, bc_cloud_weights, wc_cloud_weights, federation_round, X_malicious, = args
    rng = np.random.default_rng()
    n_to_install_apps = rng.binomial(
        n=n_max_apps,
        p=p_install)
    for i in range(n_to_install_apps):
        client.install_app(p_malware=p_malware)
    n_to_delete_apps = rng.binomial(
        n=n_max_apps,
        p=p_install)
    for i in range(n_to_delete_apps):
        client.delete_app()
    X = client.X_installed
    y_true = client.y_installed

    no_lim_pred, no_lim_weights = safew(
        baseline_model=baseline_model,
        base_models=base_models,
        X=X,
    )

    new_weights = np.mean(
        [cloud_weights, no_lim_weights],
        axis=0)
    bc_new_weights = np.mean(
        [bc_cloud_weights, no_lim_weights],
        axis=0)
    wc_new_weights = np.mean(
        [wc_cloud_weights, no_lim_weights],
        axis=0)

    lim_pred, lim_weights = safew(
        baseline_model=baseline_model,
        base_models=base_models,
        X=X,
        weights=new_weights,
    )
    bc_lim_pred, bc_lim_weights = safew(
        baseline_model=baseline_model,
        base_models=base_models,
        X=X,
        weights=bc_new_weights,
    )
    wc_lim_pred, wc_lim_weights = safew(
        baseline_model=baseline_model,
        base_models=base_models,
        X=X,
        weights=wc_new_weights,
    )

    client.previous_weights = client.weights
    client.weights = lim_weights
    client.honest_weights = lim_weights
    client.bc_weights = bc_lim_weights
    client.wc_weights = wc_lim_weights
    client.wc_honest_weights = wc_lim_weights

    predictions = {
        "baseline": baseline_model.predict(X),
        "no-lim": no_lim_pred,
        "lim": lim_pred,
        "bc-lim": bc_lim_pred,
        "wc-lim": wc_lim_pred,
    }
    weights = {
        "no-lim": no_lim_weights,
        "lim": lim_weights,
        "bc-lim": bc_lim_weights,
        "wc-lim": wc_lim_weights,
    }
    labels = {
        "baseline": y_true,
        "no-lim": y_true,
        "lim": y_true,
        "bc-lim": y_true,
        "wc-lim": y_true,
    }

    return {
        "client": client,
        "id": client.id_,
        "labels": labels,
        "predictions": predictions,
        "weights": weights,
    }


def update_malicious_client_worker(args):
    client, baseline_model, base_models, X_malicious, poisoned_weights, wc_poisoned_weights = args

    if client["client"].malicious and X_malicious is not None:
        X = client["client"].X_installed
        y_true = client["client"].y_installed

        poisoned_pred, _ = safew(
            baseline_model=baseline_model,
            base_models=base_models,
            X=X,
            weights=poisoned_weights,
        )
        client["labels"]["poisoned"] = y_true
        client["weights"]["poisoned"] = poisoned_weights
        client["predictions"]["poisoned"] = poisoned_pred
        client["client"].weights = poisoned_weights

        wc_poisoned_pred, _ = safew(
            baseline_model=baseline_model,
            base_models=base_models,
            X=X,
            weights=wc_poisoned_weights,
        )

        client["labels"]["wc_poisoned"] = y_true
        client["weights"]["wc_poisoned"] = wc_poisoned_weights
        client["predictions"]["wc_poisoned"] = wc_poisoned_pred
        client["client"].wc_weights = wc_poisoned_weights

    return client
